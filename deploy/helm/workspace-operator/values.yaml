# Default values for workspace-operator.
# Deploy: helm install workspace-operator . -n workspace-operator-system --create-namespace

operator:
  image:
    repository: ghcr.io/spjdevops/devplane/workspace-operator
    tag: latest
    pullPolicy: IfNotPresent
  replicas: 1
  resources:
    requests:
      cpu: 10m
      memory: 64Mi
    limits:
      cpu: 500m
      memory: 128Mi
  leaderElect: true

gateway:
  enabled: true
  image:
    repository: ghcr.io/spjdevops/devplane/workspace-gateway
    tag: latest
    pullPolicy: IfNotPresent
  replicas: 2
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      cpu: 500m
      memory: 256Mi
  workspaceNamespace: "workspaces"  # dedicated namespace for user pods/pvcs/services
  createWorkspaceNamespace: true     # create this namespace as part of helm install
  oidc:
    issuerURL: ""
    clientID: ""
    # Name of an existing Secret with keys issuer-url and client-id.
    # If set, oidc.issuerURL and oidc.clientID are ignored.
    existingSecret: ""
  tls:
    customCABundle:
      configMapName: ""
  ingress:
    enabled: false
    className: ""
    host: devplane.example.com
    tls: []

workspace:
  image:
    repository: ghcr.io/spjdevops/devplane/workspace
    tag: latest
  defaultResources:
    cpu: "2"
    memory: "4Gi"
    storage: "20Gi"
  storageClass: ""
  ai:
    # providers is the list of AI provider backends available to workspace pods.
    # Each entry requires a name (used as the opencode provider key), an endpoint
    # (OpenAI-compatible base URL), and at least one model ID.
    providers:
      - name: local
        endpoint: "http://vllm.ai-system.svc:8000"
        models:
          - deepseek-coder-33b-instruct
    # egressNamespaces is the list of Kubernetes namespaces where LLM services run.
    # Workspace pods are allowed to reach all pods in these namespaces (any port).
    # The operator joins this list into a comma-separated LLM_NAMESPACES env var.
    egressNamespaces:
      - ai-system
    # egressPorts is the list of TCP ports workspace pods are allowed to reach on
    # external IPs (0.0.0.0/0).  Covers git-over-SSH (22), HTTP/HTTPS (80/443),
    # Docker registry (5000), vLLM (8000), Nexus/Artifactory (8080/8081), and
    # Ollama (11434).  Override to restrict or expand as needed.
    # The operator joins this list into a comma-separated EGRESS_PORTS env var.
    egressPorts:
      - 22
      - 80
      - 443
      - 5000
      - 8000
      - 8080
      - 8081
      - 11434
  # idleTimeout controls how long a Running workspace may be inactive before its
  # pod is automatically stopped.  Uses Go duration syntax (e.g. "24h", "8h30m").
  # Leave empty to disable idle shutdown.
  idleTimeout: "24h"
